{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_doc.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/vrijain/NLP-/blob/master/tokenization.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Q9MiBXX5pOzW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc0335ce-b774-4e88-fe33-c1edf0000c25"
      },
      "cell_type": "code",
      "source": [
        "# This program tokenizes text by spaces\n",
        "\n",
        "import nltk\n",
        "text = \"this is john's text, isn't it?\"\n",
        "tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "tokenizer.tokenize(text)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this', 'is', \"john's\", 'text,', \"isn't\", 'it?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "kkFGqvlXpeLm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a253f4d-3bde-437c-ff5d-85f8104cbfa8"
      },
      "cell_type": "code",
      "source": [
        "# This program tokenizes text by words\n",
        "\n",
        "import nltk\n",
        "text = \"this is john's text, isn't it?\"\n",
        "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
        "tokenizer.tokenize(text)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this', 'is', 'john', \"'s\", 'text', ',', 'is', \"n't\", 'it', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "Qx1kjtq8pteU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6553e255-fdfe-4478-e126-a6f8c5eb46f7"
      },
      "cell_type": "code",
      "source": [
        "# This program tokenizes text by punctuations\n",
        "\n",
        "import nltk\n",
        "text = \"this is john's text, isn't it?\"\n",
        "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
        "tokenizer.tokenize(text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this', 'is', 'john', \"'\", 's', 'text', ',', 'isn', \"'\", 't', 'it', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    }
  ]
}